#!/usr/local/bin/python
'''
update_db.py: 	extracts activity, feeder, cognitive and scale (plus entertain
				when available) data from files generated by SimpleFeeder
				program and saves to the db

				each data type (scale, feeder and cognitive) is represented by a
				single table in the db with relations corresponding directly to the
				fields of each file type
'''
import os
import sys
import csv
import time
import json
import fnmatch
import sqlite3
import datetime

##
## FUNCTIONS
##
# finds directories in path that match pattern
def find(pattern, path, include_dir=False):
    result = []
    for root, dirs, files in os.walk(path):
		for name in (files if not include_dir else files + dirs):
			if fnmatch.fnmatch(name, pattern):
				result.append(os.path.join(root, name))
    return result


##
## MAIN
##
# make list of stations, which have a one-to-one correspondence to monkeys
STATIONS = map(str, range(401, 405) + range(501, 509) + range(601, 609) + range(801, 809))

# get configuration options
opts = {}
config_f = open('config.txt', 'r')
opts = json.load(config_f)
config_f.close()

# init data directory
archive_dir = opts["data_dir"]

# get yesterday's date, in two formats: one normal and one specifically for activity data files
# use dummies for testing
yesterday = datetime.datetime(2015, 7, 30)		#(datetime.datetime.now() - datetime.timedelta(days=1))
yesterday_str = yesterday.strftime('%b %d, %Y')
yesterday_activity_str = '{d.year}-{d.month}-{d.day:02}'.format(d=yesterday)
yesterday_scale_str = yesterday.strftime("%B_%d_%Y")

# connect to db
conn = sqlite3.connect('PCRL_phizer_study.db')
c = conn.cursor()			# and declare cursor (obj that interacts directly with db)

# get activity, feeding, cognitive and scale data for each station (monkey)
# and commit data changes for each one of those stations
for station in STATIONS:

	# find data directories
	data_dirs = find('*-' + station, archive_dir, include_dir=True)

	try:
	#only except IndexError for when find doesn't match

		# get data files from those directories
		activity_file  = find('*', find(yesterday_activity_str + '*', data_dirs[0], include_dir=True)[0])[0]
		feeder_file    = find(yesterday_str + '.FeedTest*', data_dirs[1])[0]
		cognitive_file = find(yesterday_str + 'DMSTest*', data_dirs[1])[0]
		scale_file 	   = find(yesterday_scale_str + '.csv', archive_dir)[0]

		# get activity values
		f = open(activity_file, 'r') 													#open file
		activity_lines = map( lambda line: line.replace('\n', ''), f.readlines()[7:] )	#skip first 8 lines; and clean
		f.close()

		activity_values = []
		date_time = yesterday
		fifteen_secs = datetime.timedelta(seconds=15)
		for line in activity_lines:
			date_time = date_time + fifteen_secs
			activity_values.append((str(date_time), int(line), station))

		# get cognitive values
		f = open(cognitive_file, 'r')
		cognitive_lines = map( lambda line: line.replace('\n', ''), f.readlines())
		f.close()

		cognitive_values = []
		for line in cognitive_lines:
			fields = line.split('@')
			date_time = str(datetime.datetime.strptime(fields[0][:fields[0].find('M') + 1], '%b %d, %Y %I:%M:%S %p'))
			time = 0
			try:
				time = int(fields[1])
			except ValueError:
				pass
			cognitive_values.append((date_time, time, fields[2], station))

		# get feeder values
		f = open(feeder_file, 'r')
		feeder_lines = map( lambda line: line.replace('\n', ''), f.readlines())
		f.close()

		feeder_values = []
		for line in feeder_lines:
			fields = line.split('@')
			#print fields
			date_time = str(datetime.datetime.strptime(fields[0], '%b %d, %Y %I:%M:%S %p '))
			feeder_values.append((date_time, float(fields[1]), int(fields[3]), station))

		# get scale values
		f = open(scale_file, 'r')
		scale_lines = map( lambda line: line.replace('\n', ''), f.readlines())
		f.close()

		scale_values = []
		for line in scale_lines:
			fields = map(lambda f: f.replace('\r', ''), line.split(','))
			try:
				date_time = str(datetime.datetime.strptime(yesterday_scale_str + \
				 							' ' + fields[0], '%B_%d_%Y %H:%M'))
				scale_values.append((date_time, float(fields[1]), station))
			except ValueError:
				pass

		# insert values into respective tables
		c.executemany("INSERT INTO activity (date_time, activity, monkey) VALUES (?,?,?)", activity_values)
		c.executemany("INSERT INTO cognitive (date_time, time, event, monkey) VALUES (?,?,?,?)", cognitive_values)
		c.executemany("INSERT INTO feeder (date_time, rxn_time, feeder, monkey) VALUES (?,?,?,?)", feeder_values)
		c.executemany("INSERT INTO scale (date_time, weight, monkey) VALUES (?,?,?)", scale_values)

	except IndexError:
		pass

conn.commit()
conn.close()
